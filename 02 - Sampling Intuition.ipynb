{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f29feb90-d97a-47c3-ba28-04c69efa54ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2 - Sampling Intuition & Cochran's formula\n",
    "\n",
    "Sampling is a way of gathering information about a large group by looking at a smaller part of it. This smaller part, called a sample, is chosen to represent the whole group as closely as possible. It's like tasting a spoonful of soup to get an idea of the flavor of the whole pot. By studying the sample, we can make educated guesses about the larger group, saving time and resources while still getting useful information.\n",
    "\n",
    "Sampling has a long history, dating back to the early 20th century when statisticians like William G. Cochran pioneered its use to make data collection more efficient and cost-effective. In his influential book \"Sampling Techniques,\" Cochran laid the foundation for modern sampling methods, demonstrating how to select representative samples and analyze the results to draw meaningful conclusions about larger populations.\n",
    "\n",
    "Cochran's formula for calculating the appropriate sample size is a cornerstone of modern sampling techniques. While the theory is solid, it's often helpful to build intuition around the formula through practical examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1958b2f-eca0-421e-8e65-da5c6281b674",
   "metadata": {},
   "source": [
    "#### Import functionality\n",
    "When using python code in a Jupyter notebook, the first thing is to import the libraries that provide the functionality needed to run the code. Here we use standard libraries from the [scientific python stack](https://fabienmaussion.info/scipro_ws2019/html/15-Scientific-Python.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219c4a0a-ae69-46fe-accf-ae79d6892b3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c69304f-eb78-4133-bbaf-91c83b23fed1",
   "metadata": {},
   "source": [
    "## 1 - Sample size calculation based on Cochran's formula \n",
    "\n",
    "The relationship between sample size, sampling error, and probability/proportion is at the heart of Cochran's formula.\n",
    "\n",
    "- **Sample size**: The number of observations or individuals in your sample.\n",
    "- **Sampling error**: The difference between your sample's results and the true population value. Larger samples tend to have smaller sampling errors because they better represent the whole population.\n",
    "- **Probability/Proportion**: This is the estimated percentage of the population that has a certain characteristic or opinion. It plays a fundamental role in determining the needed sample size.\n",
    "\n",
    "Imagine you're trying to guess the percentage of people in your city who prefer coffee over tea. The more people you ask (larger sample size), the more confident you can be that your guess is close to the true percentage (smaller sampling error).  But even with a small sample, if the true proportion is very extreme (like 99% prefer coffee), it's easier to get an accurate estimate than if the proportion is closer to 50/50.\n",
    "\n",
    "Cochran's formula takes all of these factors into account, allowing you to calculate the optimal sample size needed to achieve a desired level of confidence in your results while minimizing the margin of error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7a06e1-6aff-4377-b587-fe998d0e31f6",
   "metadata": {},
   "source": [
    "### 1.1 - Python implementation\n",
    "\n",
    "The formula is as follows:\n",
    "\n",
    "$n_0 = \\frac{Z^2 p (1-p)}{e^2}$,\n",
    "\n",
    "where\n",
    "- $n_0$ is the required sample size\n",
    "- $Z$ is the Z-score (e.g., 1.96 for a 95% confidence level)\n",
    "- $p$ is the estimated proportion of the population for the category that will be estimated \n",
    "- $e$ is the desired margin of error (expressed as a decimal)\n",
    "\n",
    "Here below you find the code for an implementation in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deb1f0a-f306-42f9-b66f-667f9cdfa160",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cochran_sample_size(precision, confidence_level, population_proportion):\n",
    "    \"\"\"Calculates the sample size required to estimate a population proportion using the Cochran formula.\n",
    "\n",
    "    Parameters:\n",
    "    precision (float): the desired level of precision (margin of error) as a fraction \n",
    "    confidence_level (float): the desired level of confidence as a fraction\n",
    "    population_proportion (float): the proportion of the population being estimated as a fraction\n",
    "\n",
    "    Returns:\n",
    "    The required sample size (int)\n",
    "    \"\"\"\n",
    "    \n",
    "    # this takes the z-score from the t-distribution to determine the confidence interval \n",
    "    z_score = abs(stats.norm.ppf((1 - confidence_level) / 2))\n",
    "    \n",
    "    # that is the proportion of the phenomena, and the inverse\n",
    "    p_hat = population_proportion\n",
    "    q_hat = 1 - p_hat\n",
    "    \n",
    "    # this basically is our margin of error as a function of the proportion\n",
    "    e = precision * population_proportion \n",
    "    \n",
    "    n = ((z_score**2) * p_hat * q_hat) / (e**2)\n",
    "    return np.ceil(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64647555-978c-4e67-ae85-b73f836e6f7b",
   "metadata": {},
   "source": [
    "### 1.2 - A simple example to play with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd01384-d2cb-4b73-8f01-338e897f06de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------\n",
    "# INPUTS\n",
    "precision = 0.1             # 10% Margin of Error\n",
    "confidence_level = 0.95     # 95% CI\n",
    "population_proportion = 0.5 # 50/50 case\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "print(\n",
    "    f'Sample size for a '\n",
    "    f'an expected {population_proportion*100} proportion at a '\n",
    "    f'{confidence_level*100} confidence interval with a '\n",
    "    f'{precision*100} margin of error is: ' \n",
    ")\n",
    "      \n",
    "print(\n",
    "    int(cochran_sample_size(precision, confidence_level, population_proportion))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdae4879-8b24-453f-8482-104c6e2df0cc",
   "metadata": {},
   "source": [
    "### 1.3 - Rare events\n",
    "\n",
    "When it comes to rare events, sampling becomes even more challenging. Imagine trying to estimate the prevalence of a rare disease or the likelihood of a natural disaster.  These events are, by definition, infrequent, making it difficult to gather a representative sample. Cochran's formula can still be applied in such cases, but it's important to be aware of the limitations.  The smaller the expected proportion, the larger the required sample size to achieve a reasonable level of confidence. In some situations, it may not be feasible to collect a large enough sample to accurately estimate the prevalence of a rare event.\n",
    "\n",
    "This is where other sampling techniques, like stratified sampling or adaptive sampling, can be helpful. These methods can help to increase the representation of rare events in the sample, but they also introduce additional complexity and require careful consideration.\n",
    "\n",
    "The following code creates a figure that plots the sample size as a function of proportion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bad9aa-fef7-4a9b-a91d-a9302556a03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------\n",
    "# INPUTS\n",
    "proportions= [0.1, 1, 2, 5, 10]   # a list in percentage \n",
    "moe = 0.1                         # expected MoE\n",
    "ci = 0.9                          # CI\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "d ={}\n",
    "for proportion in proportions:\n",
    "    fraction = proportion/100 \n",
    "    d[proportion] = [proportion, fraction*(1-fraction), cochran_sample_size(moe, ci, fraction)]\n",
    "\n",
    "# plotting\n",
    "df = pd.DataFrame.from_dict(d, orient='index', columns=['Proportion (in %)', 'Variance', 'Sample Size'])\n",
    "ax = sns.scatterplot(data=df, x='Sample Size', y='Proportion (in %)', hue='Proportion (in %)', legend='full', palette='turbo', size='Proportion (in %)')\n",
    "_ = ax.set_title('Sample size as a function of proportion for a 90% CI and a 20% MoE')\n",
    "sns.despine(ax=ax, trim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9209df-6744-403f-9585-dead82097c84",
   "metadata": {},
   "source": [
    "## 2 - Expected relative margin of error for certain sample sizes and proportions\n",
    "\n",
    "The following formula is an inverted version of the Cochran's formula. Given the proportion of the category, sample size and applied confidence interval, the relative margin of error can be calculated. This is usually the uncertainty reported in sample-based assessments, as it tells us the range of where our true value is likely to be. Since our estimate almost never equals the true value, the uncertainty around the estimate is as important as the actual estimate itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f00fe0-4fff-4fdd-b06b-b9869e86529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_of_error(sample_size, confidence_level, population_proportion):\n",
    "    \"\"\"Calculates the margin of error for estimating a population proportion based on the Cochran formula.\n",
    "\n",
    "    Parameters:\n",
    "    sample_size (int): the number of observations in the sample\n",
    "    confidence_level (float): the desired level of confidence as a fraction\n",
    "    population_proportion (float): the estimated proportion of the population as a fraction\n",
    "\n",
    "    Returns:\n",
    "    The margin of error (float)\n",
    "    \"\"\"\n",
    "\n",
    "    # Z-score from the standard normal distribution for the given confidence level\n",
    "    z_score = abs(stats.norm.ppf((1 - confidence_level) / 2))\n",
    "\n",
    "    # Proportion of the phenomena and its inverse\n",
    "    p_hat = population_proportion\n",
    "    q_hat = 1 - p_hat\n",
    "\n",
    "    # Calculate the margin of error using the inverse of Cochran's formula\n",
    "    margin_error = z_score * np.sqrt((p_hat * q_hat) / sample_size / p_hat**2) \n",
    "\n",
    "    return margin_error "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada9a9a4-5bd2-40a5-afd5-1e796f335641",
   "metadata": {},
   "source": [
    "### 2.1 - Example calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b2d6a9-9ec2-476f-9e47-00499cae520f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------\n",
    "# INPUTS\n",
    "sample_size = 5000           # 1000 Samples\n",
    "confidence_level = 0.9       # 90% CI\n",
    "population_proportion = 0.1  # fraction, i.e. 0.1 = 10%\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "error = margin_of_error(sample_size, confidence_level, population_proportion) * 100\n",
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff45e67-48cc-44b6-b737-8557a8a479d2",
   "metadata": {},
   "source": [
    "### 2.2 - Plotting various combinations\n",
    "\n",
    "Here we calculate the relative margin of error for various combinations of sample size and proportions and plot it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfa062c-8429-4240-a737-f2acf37fb235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------\n",
    "# INPUTS\n",
    "confidence_interval = 0.95                # 90 % confidence interval\n",
    "proportions = [0.1, 0.2, 0.5, 0.75, 1]   # list of proportions we want to show \n",
    "sample_sizes = range(1000, 22000, 2000)  # range of sample size (start, end, step)\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "d, i = {}, 0\n",
    "for proportion in proportions:  #\n",
    "    for sample_size in sample_sizes: # number of samples to loop over\n",
    "        d[i] = [margin_of_error(sample_size, confidence_interval, proportion/100) * 100, sample_size, proportion]\n",
    "        i += 1\n",
    "\n",
    "# create dataframe\n",
    "final = pd.DataFrame.from_dict(d, orient='index')\n",
    "final.columns = ['MoE (in %)', 'Sample Size', 'Proportion (in %)']\n",
    "\n",
    "# do the plotting\n",
    "palette = sns.color_palette(\"magma\", n_colors=len(proportions))\n",
    "ax = sns.barplot(final, y='MoE (in %)', x='Sample Size', hue='Proportion (in %)', palette=palette)\n",
    "ax.yaxis.grid(True)\n",
    "ax = sns.despine(ax=ax, trim=True, offset=10)\n",
    "_ = plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76149fb6-e06d-4809-83ea-1994fc9d769b",
   "metadata": {},
   "source": [
    "### 2.3 - Relative versus absolute margin of error\n",
    "\n",
    "The above shown examples only consider the relative margin of error. This is useful when \"hunting\" for a certain level of precision. However, it is also important to consider the absolute margin of error, whihc is what is shown here. In practice, a small relative error over a larger proportion, in absolute terms, might still be larger than a huge relative error over a small proportion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbeb648-1941-4bb3-8dbf-f2eef20b568b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------\n",
    "# INPUTS\n",
    "confidence_interval = 0.95                # 95 % confidence interval\n",
    "proportions = [0.1, 0.2, 0.3, 0.4, 0.5]   # list of proportions we want to show \n",
    "sample_sizes = range(1000, 22000, 4000)   # sample size (start, end, step)\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "d, i = {}, 0\n",
    "for proportion in proportions:\n",
    "    for sample_size in sample_sizes:\n",
    "        d[i] = [margin_of_error(sample_size, confidence_interval, proportion/100) * 100, sample_size, proportion]\n",
    "        i += 1\n",
    "\n",
    "# create dataframe\n",
    "final = pd.DataFrame.from_dict(d, orient='index')\n",
    "final.columns = ['MoE (in %)', 'Sample Size', 'Proportion (in %)']\n",
    "\n",
    "final['Area'] = 100000 * final['Proportion (in %)']\n",
    "final['MoE absolute'] = final['MoE (in %)']/100 * final['Area']\n",
    "#display(final)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "fig, ax = plt.subplots(2, 3, figsize=(15, 10), sharex=True, sharey=True)\n",
    "ax = ax.flatten()\n",
    "\n",
    "for p in range(len(sample_sizes)):\n",
    "\n",
    "    sub_final = final[final['Sample Size'] == sample_sizes[p]]\n",
    "    ax[p] = sns.barplot(\n",
    "        \n",
    "        data=sub_final, x='Proportion (in %)', y='Area', hue='Proportion (in %)', palette=palette, legend=False, ax=ax[p]\n",
    "    )\n",
    "    \n",
    "    for idx, container in enumerate(ax[p].containers):\n",
    "        ax[p].bar_label(container, labels=[f'({round(sub_final[\"MoE (in %)\"], 2).values[idx]} %)'], padding=3)\n",
    "        ax[p].bar_label(container, labels=[f'{round(sub_final[\"MoE absolute\"], 2).values[idx]}'], padding=15)\n",
    "    \n",
    "    # Get bar positions (this might require inspecting the 'ax' object)\n",
    "    bar_positions = [patch.get_x() + patch.get_width() / 2 for patch in ax[p].patches][:len(final)]\n",
    "    ax[p].errorbar(bar_positions, sub_final['Area'], yerr=sub_final['MoE absolute'], fmt='none', ecolor='darkgrey', capsize=5)\n",
    "    ax[p].set_title(f'Sample Size of {sample_sizes[p]}')\n",
    "\n",
    "plt.suptitle('Confidence Intervals as a function of Sample size')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffd3787-0279-4312-af46-f3058947f22c",
   "metadata": {},
   "source": [
    "## 3 - Practical examples of deforestation based on country statistics\n",
    "\n",
    "Here we translate the above described interrelationship between sample size, proportion and margin of error to tree cover loss statistics based on Hansen's Global Forest Change product. Note that this dataset relates to tree cover and not necessarily forest. \n",
    "\n",
    "The proportion is calculated based on the area of tree cover loss divided by the total area of the country. This code might take a while to run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c34f713-22fb-4442-a94f-b8ea92ed5e3b",
   "metadata": {},
   "source": [
    "### 3.1 - Helper functions\n",
    "\n",
    "The first function will extract tree cover loss and total country area from Hansen's dataset.\n",
    "The second function is to plot the values extracted as a function of proportion of tree cover loss to total land area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6beb73-d576-4398-921e-0fd346662bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "ee.Initialize()\n",
    "\n",
    "def get_area_statistics(aoi, start, end):\n",
    "\n",
    "    # load hansen image\n",
    "    hansen = ee.Image('UMD/hansen/global_forest_change_2023_v1_11')\n",
    "    \n",
    "    # create a pixel area image for area of full aoi\n",
    "    aoi_area = (\n",
    "        ee.Image(1).reproject(hansen.projection().atScale(30)).rename('aoi_area')\n",
    "    )\n",
    "\n",
    "    # get actual forest area\n",
    "    loss = hansen.select(\"lossyear\").gte(start).And(hansen.select(\"lossyear\").lte(end)).rename('loss')\n",
    "    layer = loss.addBands(aoi_area)\n",
    "    return layer.multiply(ee.Image.pixelArea()).reduceRegion(**{\n",
    "        \"reducer\": ee.Reducer.sum(),\n",
    "        \"geometry\": aoi,\n",
    "        \"scale\": 100,\n",
    "        \"maxPixels\": 1e14,\n",
    "    }).getInfo()\n",
    "\n",
    "def plot_country_stats(d):\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(d, orient='index', columns=['Country', 'Proportion of Change (in %)', 'Sample Size', 'Area of Change (km2)', 'Total area'])\n",
    "    ax = sns.scatterplot(data=df, x='Sample Size', y='Proportion of Change (in %)', hue='Country', legend=True, size='Area of Change (km2)')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper right', ncol=2)\n",
    "    _ = ax.set_title('Sample size as a function of proportion for a 90% CI and a 20% MoE')\n",
    "    sns.despine(ax=ax, trim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d1c69c-7328-4e62-84bd-e50d59f02467",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "countries = ['Kenya', 'Liberia', 'Uganda', 'Ethiopia', 'Paraguay', 'Bolivia', 'Burundi']\n",
    "gaul = ee.FeatureCollection(\"FAO/GAUL/2015/level1\")\n",
    "\n",
    "# those years are inclusive, select the same for a 1 year period\n",
    "startyear = 2020\n",
    "endyear = 2020\n",
    "\n",
    "# loop over countries, and extract the areas\n",
    "d ={}\n",
    "for country in countries:\n",
    "\n",
    "    aoi = gaul.filter(ee.Filter.eq(\"ADM0_NAME\", country)).union()\n",
    "    areas = get_area_statistics(aoi, startyear-2000, endyear-2000)\n",
    "    proportion = areas['loss']/areas['aoi_area']\n",
    "    d[country] = [country, proportion*100, cochran_sample_size(0.20, 0.90, proportion), areas['loss']/1000000, areas['aoi_area']/1000000]\n",
    "\n",
    "# plot the results\n",
    "plot_country_stats(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e5b52b-6efc-49a9-b3c5-7cee19601fa7",
   "metadata": {},
   "source": [
    "## 4 - Concluding remarks\n",
    "\n",
    "This notebook is intended to build some intuition around sampling theory starting from Cochran's formula that builds the base for the sample based estimation process. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": " (venv) Sample Based Area Estimation",
   "language": "python",
   "name": "venv-esbae_notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
